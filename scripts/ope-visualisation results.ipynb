{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections.abc import Iterable\n",
    "import functools\n",
    "import itertools\n",
    "import operator\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.use('pgf')\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",  # use serif/main font for text elements\n",
    "    \"text.usetex\": True,     # use inline math for ticks\n",
    "    \"pgf.rcfonts\": False,    # don't setup fonts from rc parameters\n",
    "    \"text.latex.preamble\":  [r\"\"\"\\usepackage{amssymb}\"\"\", r'\\usepackage{amsmath}'],\n",
    "    })\n",
    "# mpl.verbose.level = 'debug-annoying'\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import numpy as np\n",
    "import numpy_ext as npe\n",
    "import math\n",
    "import random\n",
    "from pprint import pprint\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import poisson\n",
    "from scipy.sparse import hstack, vstack, csr_matrix\n",
    "import scipy\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import joblib\n",
    "\n",
    "import seaborn as sns\n",
    "import utils\n",
    "import sys\n",
    "\n",
    "from config import demographics, vital_sign_vars, lab_vars, treatment_vars, vent_vars, guideline_vars, ffill_windows_clinical, SAMPLE_TIME_H\n",
    "from config import fio2_bins, peep_bins, tv_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/ope_results.csv'\n",
    "safety_file = 'data/safety_results.csv'\n",
    "ope_wis = pd.read_csv(file)\n",
    "safety = pd.read_csv(safety_file)\n",
    "\n",
    "ope_wis = pd.merge(ope_wis, safety, suffixes=['', '_left',], on=['seed', 'algorithm', 'unsafety_prob_train', 'shaping', 'safety', 'scalar'])\n",
    "\n",
    "REWARD_RANGE = (-100, 100)\n",
    "RR_SIZE = max(REWARD_RANGE) - min(REWARD_RANGE)\n",
    "N_BOOT = 2000\n",
    "\n",
    "# TEXTWIDTH=390.0 # AI in MEDICINE\n",
    "TEXTWIDTH=341.43289 # Dissertation\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope_wis.loc[:, 'algorithm'] = ope_wis.algorithm.str.replace('behavior', 'IL')\n",
    "ope_wis.loc[:, 'algorithm'] = ope_wis.algorithm.str.replace('observed', 'O')\n",
    "ope_wis.loc[:, 'algorithm'] = ope_wis.algorithm.str.replace('softmax', 'QL$_S$')\n",
    "ope_wis.loc[:, 'algorithm'] = ope_wis.algorithm.str.replace('greedy', 'QL$_D$')\n",
    "ope_wis.loc[:, 'algorithm'] = ope_wis.algorithm.str.replace('mixed', 'M')\n",
    "    \n",
    "ope_wis['norm_scalar'] = ope_wis['scalar'] / RR_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ope_wis = ope_wis[ope_wis.algorithm != 'G']\n",
    "# ope_wis = ope_wis[ope_wis.seed < 10]\n",
    "# ope_wis = ope_wis[ope_wis.unsafety_prob_train == 1.0]\n",
    "# ope_wis = ope_wis[ope_wis.norm_scalar == 0.02]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope_wis.shaping.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds = ope_wis.seed.unique()\n",
    "# algorithms = ope_wis.algorithm.unique()\n",
    "# settings = ope_wis.train_test.unique()\n",
    "# shaping = ope_wis.shaping.unique()\n",
    "\n",
    "# experiments = itertools.product(seeds, algorithms, settings)\n",
    "cis_train = []\n",
    "cis_test = []\n",
    "for index, experiment in ope_wis.iterrows():\n",
    "    mean = experiment['phwis']\n",
    "    if experiment['train_test'] == 'train':\n",
    "        n = experiment['n_train']\n",
    "        cis = cis_train\n",
    "    elif experiment['train_test'] == 'test':\n",
    "        n = experiment['n_test']\n",
    "        cis = cis_test\n",
    "    else:\n",
    "        raise ValueError('Only train and test results supported for now')\n",
    "    ci_low, ci_up = utils.var_to_ci_cheb(experiment['var'], mean, n)\n",
    "    ci_low = max(ci_low, -100)\n",
    "    ci_up = min(ci_up, 100)\n",
    "    cis.append([experiment['seed'], experiment['algorithm'], experiment['unsafety_prob'], experiment['norm_scalar'], mean, ci_low, ci_up, experiment['hcope5'], experiment['am']])\n",
    "\n",
    "cis_test = pd.DataFrame(cis_test, columns=['seed', 'algorithm', 'unsafety_prob', 'norm_scalar', 'phwis', 'ci_l', 'ci_u', 'hcope5', 'am'])\n",
    "cis_train = pd.DataFrame(cis_train, columns=['seed', 'algorithm', 'unsafety_prob', 'norm_scalar', 'phwis', 'ci_l', 'ci_u', 'hcope5', 'am'])\n",
    "\n",
    "cis_test['setup'] = cis_test[['algorithm', 'norm_scalar', 'unsafety_prob']].apply(lambda x: '-'.join(map(str, x)), axis=1)\n",
    "cis_train['setup'] = cis_train[['algorithm', 'norm_scalar', 'unsafety_prob']].apply(lambda x: '-'.join(map(str, x)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setup, means in cis_test.groupby('setup')['phwis']:\n",
    "    mean = means.mean()\n",
    "    std = means.std()\n",
    "    print(setup, mean, std)\n",
    "    print(scipy.stats.norm.interval(.95, loc=mean, scale=std/math.sqrt(len(means))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_setup_scalar(row):\n",
    "    rnp = row.to_numpy()\n",
    "    alg, safe_scalar, mixing_scalar = rnp[0], rnp[1], rnp[2]\n",
    "    if alg in {'O', 'IL'}:\n",
    "        return alg\n",
    "    elif alg in {'QL$_D$', 'QL$_S$'}:\n",
    "        return '{}\\nc={}'.format(alg, safe_scalar)\n",
    "    elif alg in 'M':\n",
    "        return '{}\\nc={}'.format(alg, mixing_scalar)\n",
    "\n",
    "def to_setup(row):\n",
    "    rnp = row.to_numpy()\n",
    "    alg, safe_scalar, mixing_scalar = rnp[0], rnp[1], rnp[2]\n",
    "    if alg in {'O', 'IL'}:\n",
    "        return alg\n",
    "    elif alg in {'QL$_D$', 'QL$_S$'}:\n",
    "        return '{}'.format(alg)\n",
    "    elif alg in 'M':\n",
    "        return '{}'.format(alg)\n",
    "\n",
    "def setup_key(setup):\n",
    "    order = pd.Series([float('-inf'),] * len(setup))\n",
    "    order[setup == 'O'] = 0\n",
    "    order[setup == 'IL'] = 1\n",
    "    order[setup.str.contains('QL$_D$')] = setup.str.split('=').str[1].astype('float') * 200 + 1\n",
    "    order[setup.str.contains('QL$_S$')] = setup.str.split('=').str[1].astype('float') * 200 + 2\n",
    "    order[setup.str.contains('M')] = setup.str.split('=').str[1].astype('float') * 200 + 2\n",
    "    return order\n",
    "\n",
    "def algorithm_key(algorithm):\n",
    "    order = pd.Series([float('inf'),] * len(setup))\n",
    "    order[algorithm == 'O'] = 1\n",
    "    order[algorithm == 'IL'] = 2\n",
    "    order[algorithm == 'QL$_D$'] = 3\n",
    "    order[algorithm == 'QL$_S$'] = 4\n",
    "#     order[setup.str.contains('M')] = setup.str.split('=').str[1].astype('float') * 200 + 2\n",
    "    return order\n",
    "\n",
    "def safety_setup(row):\n",
    "    rnp = row.to_numpy()\n",
    "    unsafety_train, unsafety_final = rnp[0], rnp[1]\n",
    "    if unsafety_final == 1.0:\n",
    "        return 'Unsafe'\n",
    "    elif unsafety_final == 0.0 and unsafety_train == 0.0:\n",
    "        return 'Q-function'\n",
    "    elif unsafety_final == 0.0 and unsafety_train == 1.0:\n",
    "        return 'Policy'\n",
    "    else:\n",
    "        raise ValueError('Unknown safety combination {}'.format(rnp))\n",
    "\n",
    "ope_wis['setup'] = ope_wis[['algorithm', 'norm_scalar', 'mixing_prob']].apply(to_setup, axis=1)\n",
    "ope_wis['setup_scalar'] = ope_wis[['algorithm', 'norm_scalar', 'mixing_prob']].apply(to_setup_scalar, axis=1)\n",
    "ope_wis['safety'] = ope_wis[['unsafety_prob_train', 'unsafety_prob']].apply(safety_setup, axis=1)\n",
    "ope_wis['compliance'] = ope_wis.safety\n",
    "ope_wis['compliance'] = ope_wis.compliance.str.replace('Unsafe', 'Unconstr\\'nd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope_wis.compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_size(width_pt, fraction=1, times=1, subplots=(1, 1), buffer=0.0):\n",
    "    \"\"\"Set figure dimensions to sit nicely in our document.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width_pt: float\n",
    "            Document width in points\n",
    "    fraction: float, optional\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "    subplots: array-like, optional\n",
    "            The number of rows and columns of subplots.\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "    \"\"\"\n",
    "    # Width of figure (in pts)\n",
    "    fig_width_pt = width_pt * fraction\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt \n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * (1 + buffer) * golden_ratio * (subplots[0] / subplots[1]) \n",
    "\n",
    "    return (fig_width_in, fig_height_in)\n",
    "\n",
    "to_plot = ope_wis[ope_wis.norm_scalar == 0.0]\n",
    "plot_algs = list(to_plot.algorithm.unique())\n",
    "# plot_algs.remove('QL')\n",
    "plot_data = to_plot[\n",
    "    ope_wis.algorithm.isin(plot_algs) &\n",
    "    ope_wis.unsafety_prob.isin({0,1})].sort_values('setup', key=setup_key).copy()\n",
    "plot_data.loc[:, 'algorithm'] = plot_data.setup\n",
    "# plot_data = plot_data.sort_values('algorithm', key=algorithm_key)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, sharey=True, figsize=(15,5))\n",
    "hue_order=sorted(plot_data.compliance.unique(), reverse=True)\n",
    "MARKERS = ['^', 'o', 'v', 's']\n",
    "LINESTYLES = ['solid', 'dashed','dotted']\n",
    "\n",
    "\n",
    "subplots= (3,2)\n",
    "fig = plt.figure(figsize=set_size(TEXTWIDTH, fraction=1.1, subplots=subplots, buffer=0.4))\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(subplots[0], subplots[1], figsize=set_size(TEXTWIDTH, fraction=1.0, subplots=subplots), sharex='col')\n",
    "# ax[-1][-1].axis('off')\n",
    "# sns.pointplot(data=plot_data[plot_data.train_test == 'train'], x='setup', y='phwis', hue='unsafety_prob', hue_order=hue_order, join=False, dodge=True, ax=ax[0], n_boot=N_BOOT)\n",
    "dodge=0.5\n",
    "errwidth=1.0\n",
    "ax_1 = fig.add_subplot(3,2,1)\n",
    "ax_i = ax_1\n",
    "sns.pointplot(data=plot_data[plot_data.train_test == 'test'],\n",
    "              y='algorithm',\n",
    "              x='fqe',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "#               linestyles=LINESTYLES,\n",
    "              ax=ax_i,\n",
    "              linestyle=\"none\",\n",
    "              err_kws={\"color\": \"black\"},\n",
    "              dodge=dodge,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "# ax_i.set_title('FQE')\n",
    "ax_i.set_title('Model-based')\n",
    "ax_i.get_legend().remove()\n",
    "ax_i.set_xlabel('Expected Return')\n",
    "ax_i.set_ylabel('')\n",
    "\n",
    "ax_i = fig.add_subplot(3,2,3, sharex=ax_1)\n",
    "plot_data_i = plot_data[(plot_data.train_test == 'test') & (plot_data.ess > 0.0)]\n",
    "# plot_data_i = plot_data[(plot_data.train_test == 'test')]\n",
    "\n",
    "sns.pointplot(data=plot_data_i,\n",
    "              y='algorithm',\n",
    "              x='phwis',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "              err_kws={\"color\": \"black\"},\n",
    "              ax=ax_i,\n",
    "              linestyle=\"none\",\n",
    "              dodge=dodge,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "ax_i.get_legend().remove()\n",
    "ax_i.set_xlabel('Expected Return')\n",
    "ax_i.set_ylabel('')\n",
    "ax_i.set_title('Inverse Propensity Scoring')\n",
    "\n",
    "ax_i = fig.add_subplot(3,2,5, sharex=ax_1)\n",
    "sns.pointplot(data=plot_data[plot_data.train_test == 'test'],\n",
    "              y='algorithm',\n",
    "              x='phwdr',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "#               linestyles=LINESTYLES,\n",
    "              err_kws={\"color\": \"black\"},\n",
    "              ax=ax_i,\n",
    "              linestyle=\"none\",\n",
    "              dodge=dodge,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "ax_i.get_legend().remove()\n",
    "# ax[2].legend()\n",
    "ax_i.set_ylabel('')\n",
    "ax_i.set_title('Hybrid')\n",
    "ax_i.set_xlabel('Expected Return')\n",
    "\n",
    "ax_i = fig.add_subplot(3,2,2)\n",
    "sns.pointplot(data=plot_data[plot_data.train_test == 'test'],\n",
    "              y='algorithm',\n",
    "              x='safety_policy',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "#               linestyles=LINESTYLES,\n",
    "              err_kws={\"color\": \"black\"},\n",
    "              ax=ax_i,\n",
    "              linestyle=\"none\",\n",
    "              dodge=dodge,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "ax_i.get_legend().remove()\n",
    "ax_i.set_xlim(0,1.1)\n",
    "# ax[2].legend()\n",
    "ax_i.set_ylabel('')\n",
    "ax_i.set_xlabel(r'$P(a \\in A_{\\mathcal{C}})$')\n",
    "ax_i.set_title('Compliance')\n",
    "\n",
    "ax_i = fig.add_subplot(3,2,4)\n",
    "sns.pointplot(data=plot_data[plot_data.train_test == 'test'],\n",
    "              y='algorithm',\n",
    "              x='ess',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "#               linestyles=LINESTYLES,\n",
    "              err_kws={\"color\": \"black\"},\n",
    "              ax=ax_i,\n",
    "              linestyle=\"none\",\n",
    "              dodge=dodge,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "ax_i.get_legend().remove()\n",
    "ax_i.legend(loc='upper right',title='', handletextpad=.1)\n",
    "ax_i.set_xscale('symlog')\n",
    "ax_i.set_xlim(-1.0,10e3)\n",
    "# ax[2].legend()\n",
    "ax_i.set_ylabel('')\n",
    "ax_i.set_xlabel('ESS')\n",
    "ax_i.set_title('Effective sample size')\n",
    "\n",
    "\n",
    "# ax[1].axhline(y=16.717279190924337, color='black')\n",
    "# ax[1].axhline(y=73.3723122454629, color='black')\n",
    "# plt.suptitle('')\n",
    "fig.tight_layout()\n",
    "plt.savefig('/tmp/all_ope.pdf', dpi=1200)\n",
    "# plt.savefig('/tmp/all_ope.png', dpi=1200)\n",
    "plt.savefig('/tmp/all_ope.pgf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_d = ope_wis[(ope_wis.algorithm == 'QL$_D$')]\n",
    "hue_order=sorted(q_d.compliance.unique(), reverse=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=set_size(TEXTWIDTH, fraction=0.7))\n",
    "\n",
    "ax = sns.pointplot(data=q_d[q_d.train_test == 'test'],\n",
    "              y='fqe',\n",
    "              x='scalar',\n",
    "              hue='compliance',\n",
    "              hue_order=hue_order,\n",
    "              markers=MARKERS,\n",
    "              err_kws={\"color\": \"black\"},\n",
    "              linestyles=\"none\",\n",
    "                   ax=ax,\n",
    "              dodge=0.4,\n",
    "              n_boot=N_BOOT,\n",
    "              errwidth=errwidth,\n",
    "              scale=0.8)\n",
    "# ax.get_legend().remove()\n",
    "ax.legend(loc='best',title='', handletextpad=.1)\n",
    "ax.set_ylabel('Expected Return')\n",
    "ax.set_xlabel('$c$')\n",
    "ax.set_title('QL$_D$ with reward shaping')\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/shaping.pdf')\n",
    "# plt.savefig('/tmp/shaping.png', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_filters = (q_d.shaped == False) & (q_d.algorithm == 'QL$_D$')\n",
    "q_d_qsafe = q_d[shared_filters & (q_d.safety == 'Q-function')].sort_values('seed')\n",
    "q_d_psafe = q_d[shared_filters & (q_d.safety == 'Policy')].sort_values('seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare whether the safety criterion should be included in the Q function definition or not\n",
    "print('Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)')\n",
    "print('fqe: {}'.format(scipy.stats.wilcoxon(q_d_qsafe.fqe, q_d_psafe.fqe, alternative='greater')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = plot_data[plot_data.algorithm == 'O'].sort_values('seed')\n",
    "il_u = plot_data[(plot_data.algorithm == 'IL') & (plot_data.safety == 'Unsafe')].sort_values('seed')\n",
    "il_psafe = plot_data[(plot_data.algorithm == 'IL') & (plot_data.safety == 'Policy')].sort_values('seed')\n",
    "\n",
    "q_d_qsafe = plot_data[(plot_data.algorithm == 'QL$_D$') & (plot_data.safety == 'Q-function') & (plot_data.shaped == False)].sort_values('seed')\n",
    "q_d_psafe = plot_data[(plot_data.algorithm == 'QL$_D$') & (plot_data.safety == 'Policy') & (plot_data.shaped == False)].sort_values('seed')\n",
    "q_d_u = plot_data[(plot_data.algorithm == 'QL$_D$') & (plot_data.safety == 'Unsafe') & (plot_data.shaped == False)].sort_values('seed')\n",
    "\n",
    "q_s_qsafe = plot_data[(plot_data.algorithm == 'QL$_S$') & (plot_data.safety == 'Q-function') & (plot_data.shaped == False)].sort_values('seed')\n",
    "q_s_psafe = plot_data[(plot_data.algorithm == 'QL$_S$') & (plot_data.safety == 'Policy') & (plot_data.shaped == False)].sort_values('seed')\n",
    "q_s_u = plot_data[(plot_data.algorithm == 'QL$_S$') & (plot_data.safety == 'Unsafe') & (plot_data.shaped == False)].sort_values('seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare whether the safety criterion should be included in the Q function definition or not\n",
    "print('Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)')\n",
    "print('il_u: {}'.format(scipy.stats.wilcoxon(il_u.phwis, o.phwis, alternative='less')))\n",
    "print('il_psafe: {}'.format(scipy.stats.wilcoxon(il_psafe.phwis, o.phwis, alternative='less')))\n",
    "print('q_d_u: -')\n",
    "print('q_d_qsafe: -')\n",
    "nonzero_seeds = q_d_psafe[q_d_psafe.phwis !=0].seed\n",
    "print('q_d_psafe: {}'.format(scipy.stats.wilcoxon(q_d_psafe.phwis[q_d_psafe.seed.isin(nonzero_seeds)], o[o.seed.isin(nonzero_seeds)].phwis, alternative='less')))\n",
    "print('q_s_u: {}'.format(scipy.stats.wilcoxon(q_s_u.phwis, o.phwis, alternative='less')))\n",
    "print('q_s_qsafe: {}'.format(scipy.stats.wilcoxon(q_s_qsafe.phwis, o.phwis, alternative='less')))\n",
    "print('q_s_psafe: {}'.format(scipy.stats.wilcoxon(q_s_psafe.phwis, o.phwis, alternative='less')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare whether the safety criterion should be included in the Q function definition or not\n",
    "print('Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)')\n",
    "print('il_u: {}'.format(scipy.stats.wilcoxon(il_u.phwdr, o.phwdr, alternative='less')))\n",
    "print('il_psafe: {}'.format(scipy.stats.wilcoxon(il_psafe.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_d_u: {}'.format(scipy.stats.wilcoxon(q_d_u.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_d_qsafe: {}'.format(scipy.stats.wilcoxon(q_d_qsafe.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_d_psafe: {}'.format(scipy.stats.wilcoxon(q_d_psafe.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_s_u: {}'.format(scipy.stats.wilcoxon(q_s_u.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_s_qsafe: {}'.format(scipy.stats.wilcoxon(q_s_qsafe.phwdr, o.phwdr, alternative='less')))\n",
    "print('q_s_psafe: {}'.format(scipy.stats.wilcoxon(q_s_psafe.phwdr, o.phwdr, alternative='less')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare whether the safety criterion should be included in the Q function definition or not\n",
    "print('Compare safety Q-function to Policy safety (nonparametric Wilcoxon signed-rank test)')\n",
    "print('phwdr: {}'.format(scipy.stats.wilcoxon(ql_qsafe.phwdr, ql_psafe.phwdr, alternative='less').pvalue))\n",
    "print('phwis: {}'.format(scipy.stats.wilcoxon(ql_qsafe.phwis, ql_psafe.phwis, alternative='less').pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistic_row(datarow, statistic=np.mean, cols = ['phwis', 'fqe', 'phwdr', 'ess'], prec=0.2):\n",
    "    for c in cols:\n",
    "        if c != 'ess':\n",
    "            loc, (ci_l, ci_u) = utils.bootstrap_ci(datarow[c], stat=statistic, conf=0.95)\n",
    "            print((\" {:\" + str(prec) + \"f} & {:\"+str(prec) +\"f}-{:\"+str(prec)+\"f} &\").format(loc, ci_l, ci_u), end=\" \")\n",
    "        else:\n",
    "            print((\" {:\" + str(prec) + \"f} \").format(statistic(datarow[c])), end=\"\\\\\\\\\\n\")\n",
    "\n",
    "            \n",
    "for stat in [\n",
    "    ope_wis[ope_wis.algorithm == 'O'],\n",
    "    il_unsafe,\n",
    "    il_psafe,\n",
    "    ql_unsafe,\n",
    "    ql_qsafe,\n",
    "    ql_psafe\n",
    "]:\n",
    "    print_statistic_row(stat, np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "statistic = np.mean \n",
    "# statistic = np.median\n",
    "print('Observed')\n",
    "print(utils.bootstrap_ci(ope_wis[ope_wis.algorithm == 'O'].phwdr))\n",
    "print('IL-unsafe')\n",
    "print(utils.bootstrap_ci(il_unsafe.phwdr))\n",
    "print(utils.bootstrap_ci(il_unsafe.phwis))\n",
    "print(utils.bootstrap_ci(il_unsafe.fqe))\n",
    "\n",
    "print('IL-psafe')\n",
    "print(utils.bootstrap_ci(il_psafe.phwdr))\n",
    "print(utils.bootstrap_ci(il_psafe.phwis))\n",
    "print(utils.bootstrap_ci(il_psafe.fqe))\n",
    "print('QL-unsafe')\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].phwdr))\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].phwis))\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].fqe))\n",
    "print('QL-qsafe')\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].phwdr))\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].phwis))\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].fqe))\n",
    "\n",
    "print('QL-psafe')\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].phwdr))\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].phwis))\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].fqe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?utils.bootstrap_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = False\n",
    "# statistic = np.mean \n",
    "statistic = np.median\n",
    "print('Observed')\n",
    "print(utils.bootstrap_ci(ope_wis[ope_wis.algorithm == 'O'].phwdr, statistic))\n",
    "print(utils.bootstrap_ci(ope_wis[ope_wis.algorithm == 'O'].phwis, statistic))\n",
    "print(utils.bootstrap_ci(ope_wis[ope_wis.algorithm == 'O'].fqe, statistic))\n",
    "print('IL-unsafe')\n",
    "print(utils.bootstrap_ci(il_unsafe.phwdr, statistic))\n",
    "print(utils.bootstrap_ci(il_unsafe.phwis, statistic))\n",
    "print(utils.bootstrap_ci(il_unsafe.fqe, statistic))\n",
    "\n",
    "print('IL-psafe')\n",
    "print(utils.bootstrap_ci(il_psafe.phwdr, statistic))\n",
    "print(utils.bootstrap_ci(il_psafe.phwis, statistic))\n",
    "print(utils.bootstrap_ci(il_psafe.fqe, statistic))\n",
    "\n",
    "print('QL-unsafe')\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].phwdr, statistic))\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].phwis, statistic))\n",
    "print(utils.bootstrap_ci(ql_unsafe[ql_unsafe.scalar == 0.0].fqe, statistic))\n",
    "\n",
    "print('QL-qsafe')\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].phwdr, statistic))\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].phwis, statistic))\n",
    "print(utils.bootstrap_ci(ql_qsafe[ql_qsafe.scalar == 0.0].fqe, statistic))\n",
    "\n",
    "print('QL-psafe')\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].phwdr, statistic))\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].phwis, statistic))\n",
    "print(utils.bootstrap_ci(ql_psafe[ql_psafe.scalar == 0.0].fqe, statistic))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = scipy.stats.bootstrap([ql_unsafe[ql_unsafe.scalar == 0.0].phwdr,], np.mean, confidence_level=.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.var_to_sem(ql_unsafe[ql_unsafe.scalar == 0.0].phwdr.var(), len(ql_unsafe[ql_unsafe.scalar == 0.0].phwdr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_unsafe[ql_unsafe.scalar == 0.0].phwdr.std() / math.sqrt(len(ql_unsafe[ql_unsafe.scalar == 0.0].phwdr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(ql_qsafe[ql_qsafe.scalar == 0.0].phwdr, ql_unsafe[ql_unsafe.scalar == 0.0].phwdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_rel(ql_qsafe[ql_qsafe.scalar == 0.0].phwdr, ql_unsafe[ql_unsafe.scalar == 0.0].phwdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_unsafe[ql_unsafe.scalar == 0.0][['seed','phwdr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(ql_qsafe[ql_qsafe.scalar == 0.0].phwdr, ql_unsafe[ql_unsafe.scalar == 0.0].phwdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(ql_unsafe, ql_safe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(il_unsafe, ql_unsafe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(il_safe, ql_safe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(il_unsafe, il_safe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(o, ql_safe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(o, il_safe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.wilcoxon(o, il_unsafe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = ope_wis[\n",
    "    (ope_wis.train_test == 'test') & \n",
    "    (ope_wis.algorithm == 'QL') &\n",
    "#     ((ope_wis.unsafety_prob == 0.0) |\n",
    "#      (ope_wis.unsafety_prob == 1.0))\n",
    "#     ((ope_wis.norm_scalar == 0.0) | \n",
    "#      (ope_wis.norm_scalar == .05))\n",
    "    (ope_wis.seed == 5)\n",
    "]\n",
    "\n",
    "# check[['norm_scalar', 'seed', 'mean', 'unsafety_prob']].sort_values(['seed', 'norm_scalar', 'unsafety_prob']).set_index('norm_scalar').pivot(columns=['seed', 'unsafety_prob'])\n",
    "check[['norm_scalar', 'seed', 'phwis', 'unsafety_prob']].sort_values(['seed', 'norm_scalar', 'unsafety_prob']).set_index('unsafety_prob').pivot(columns=['seed', 'norm_scalar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope_wis.scalar.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_rel(ql_safe, ql_unsafe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.ttest_ind(o, ql_unsafe, alternative='greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ope_wis.scalar.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('O:',utils.ci(o), o.mean())\n",
    "print('IL-unsafe:', utils.ci(il_unsafe), il_unsafe.mean())\n",
    "print('IL-safe:', utils.ci(il_safe), il_safe.mean())\n",
    "print('QL-unsafe:', utils.ci(ql_unsafe), ql_unsafe.mean())\n",
    "print('QL-safe:', utils.ci(ql_safe), ql_safe.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
